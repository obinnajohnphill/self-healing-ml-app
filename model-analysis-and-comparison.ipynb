{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab0c022-cf9f-4223-bf91-3f733750fef3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running analysis for Android\n",
      "Class distribution for Android before filtering:\n",
      "0          1\n",
      "1036666    1\n",
      "1036675    1\n",
      "1036674    1\n",
      "1036673    1\n",
      "          ..\n",
      "518334     1\n",
      "518333     1\n",
      "518332     1\n",
      "518331     1\n",
      "1555004    1\n",
      "Name: Label, Length: 1555005, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pycaret.classification import setup, compare_models, evaluate_model, pull\n",
    "\n",
    "# Function to perform analysis with Multinomial Naive Bayes\n",
    "def mnb_self_healing(data, labels, system_name):\n",
    "    scaler = MinMaxScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    mnb_model = MultinomialNB()\n",
    "    mnb_model.fit(data_scaled, labels)\n",
    "    predicted_labels = mnb_model.predict(data_scaled)\n",
    "    accuracy = accuracy_score(labels, predicted_labels)\n",
    "    print(f\"{system_name} MNB Accuracy:\", accuracy)\n",
    "    plot_results(data, labels, predicted_labels, system_name, 'Multinomial Naive Bayes')\n",
    "\n",
    "# Logistic Regression Analysis\n",
    "def lr_self_healing(data, labels, system_name):\n",
    "    lr_model = LogisticRegression(max_iter=1000)\n",
    "    lr_model.fit(data, labels)\n",
    "    predicted_labels = lr_model.predict(data)\n",
    "    accuracy = accuracy_score(labels, predicted_labels)\n",
    "    print(f\"{system_name} LR Accuracy:\", accuracy)\n",
    "    plot_results(data, labels, predicted_labels, system_name, 'Logistic Regression')\n",
    "\n",
    "# Linear Discriminant Analysis\n",
    "def lda_self_healing(data, labels, system_name):\n",
    "    lda_model = LinearDiscriminantAnalysis()\n",
    "    lda_model.fit(data, labels)\n",
    "    predicted_labels = lda_model.predict(data)\n",
    "    accuracy = accuracy_score(labels, predicted_labels)\n",
    "    print(f\"{system_name} LDA Accuracy:\", accuracy)\n",
    "    plot_results(data, labels, predicted_labels, system_name, 'Linear Discriminant Analysis')\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "def gbc_self_healing(data, labels, system_name):\n",
    "    gbc_model = GradientBoostingClassifier()\n",
    "    gbc_model.fit(data, labels)\n",
    "    predicted_labels = gbc_model.predict(data)\n",
    "    accuracy = accuracy_score(labels, predicted_labels)\n",
    "    print(f\"{system_name} GBC Accuracy:\", accuracy)\n",
    "    plot_results(data, labels, predicted_labels, system_name, 'Gradient Boosting Classifier')\n",
    "\n",
    "# Function to plot results\n",
    "def plot_results(data, labels, predicted_labels, system_name, model_name):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(data[:, 0], data[:, 1], c=labels, cmap='viridis', alpha=0.5, label='Actual Labels')\n",
    "    plt.scatter(data[:, 0], data[:, 1], c=predicted_labels, cmap='coolwarm', alpha=0.2, marker='x', label='Predicted Labels')\n",
    "    plt.title(f'{system_name} - {model_name}')\n",
    "    plt.xlabel('Error')\n",
    "    plt.ylabel('Warning')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Prepare the data for PyCaret analysis\n",
    "datasets = {\n",
    "    'Android': 'dataset/system-logs/multiple-system-log-dataset/preprocessed-data/Android_preprocessed.csv',\n",
    "    'Linux': 'dataset/system-logs/multiple-system-log-dataset/preprocessed-data/Linux_preprocessed.csv',\n",
    "    'Mac': 'dataset/system-logs/multiple-system-log-dataset/preprocessed-data/Mac_preprocessed.csv',\n",
    "    'Windows': 'dataset/system-logs/multiple-system-log-dataset/preprocessed-data/Windows_preprocessed.csv'\n",
    "}\n",
    "\n",
    "# Assuming the CSV files are structured with 'Error', 'Warning', and 'Label' columns\n",
    "for system_name, csv_file in datasets.items():\n",
    "    print(f\"\\nRunning analysis for {system_name}\")\n",
    "    df = pd.read_csv(csv_file)  # Load your dataset here\n",
    "    \n",
    "    # Check class distribution before filtering\n",
    "    print(f\"Class distribution for {system_name} before filtering:\")\n",
    "    print(df['Label'].value_counts())\n",
    "    \n",
    "    # Combine infrequent classes into a single 'Other' category\n",
    "    min_class_count = 2\n",
    "    value_counts = df['Label'].value_counts()\n",
    "    to_replace = value_counts[value_counts < min_class_count].index\n",
    "    df['Label'] = df['Label'].replace(to_replace, 'Other')\n",
    "    \n",
    "    # Check class distribution after handling infrequent classes\n",
    "    print(f\"Class distribution for {system_name} after handling infrequent classes:\")\n",
    "    print(df['Label'].value_counts())\n",
    "    \n",
    "    # Use the dataframe directly for PyCaret setup\n",
    "    clf_setup = setup(data=df, target='Label', session_id=42, verbose=False)\n",
    "    top4_models = compare_models(n_select=4, sort='Accuracy')\n",
    "    \n",
    "    # Pulling the performance result of the top 4 models\n",
    "    results = pull()\n",
    "    print(f\"Top 4 Models for {system_name}:\")\n",
    "    print(results.head(4))  # Displaying the top 4 models based on Accuracy\n",
    "    \n",
    "    # Example data generation (replace with actual data loading)\n",
    "    np.random.seed(42)\n",
    "    num_samples = 2000\n",
    "    data = np.random.randn(num_samples, 2)\n",
    "    labels = np.random.randint(0, 3, num_samples)\n",
    "    \n",
    "    # Scaling data for MNB\n",
    "    scaler = MinMaxScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    \n",
    "    # Call each analysis function\n",
    "    mnb_self_healing(data_scaled, labels, system_name)\n",
    "    lr_self_healing(data, labels, system_name)\n",
    "    lda_self_healing(data, labels, system_name)\n",
    "    gbc_self_healing(data, labels, system_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb72b88-c844-4746-9c12-af6fc7bbb656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf63ac2-61ca-4c55-9859-1225a896c67c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
